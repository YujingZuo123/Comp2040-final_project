步骤 1 — 探索至少三个数据集（Notebook 1）
目标

为每个数据集做结构性检查并记录数据质量问题与潜在分析问题，最终选择一个用于后续分析。

子步骤（对每个数据集重复）

加载数据

使用 pandas pd.read_csv(), pd.read_excel() 或合适的读取函数。

指定合适的参数（encoding, parse_dates, dtype 可选）。

快速检查结构

df.shape, df.info(), df.dtypes, df.head(), df.tail()。

列级别检查

列名规范化（小写、去空格、下划线替换空格）。

每列的唯一值计数：df[col].nunique() 与 df[col].value_counts(dropna=False)（注意大类列需限制输出）。

缺失值与异常值检测

df.isna().sum()、缺失比例（按列与按行）。

检查非法标记（如 -1, 'Unknown', 'N/A' 等），并记录哪些列使用这些占位符。

数值列的极端值检测：describe()、IQR、或 quantile()。

数据类型问题

判断哪些列应为日期/数值/分类/布尔，记录需要转换的列。

重复/索引检查

df.duplicated().sum()；判定是否应删除重复。

可行性与分析潜力

每列能支持哪些分析问题（列举候选分析问题）。

记录与评分

简短写一段 质量评估：样本量、缺失率、关键字段完备度、清洗工作量估计、潜在偏差。

给每个数据集打分或排序（例如：高/中/低可用性）。

要记录在 Notebook 的内容

加载代码与参数、列清单与数据类型、缺失值表、顶级质量问题、可支持的分析问题、是否列入下一步候选及理由。

步骤 2 — 评估并选定一个数据集（Notebook 1）
目标

对比三个数据集并确定最终用于深入分析的那个数据集，给出 2–3 段的选择理由。

子步骤

汇总每个数据集的优缺点（简短段落）

可分析性（关键字段）、完整性、样本量、现实意义/研究价值、清洗成本。

比较表格

建议用小表格列出每个数据集的关键指标（样本数、缺失率、关键字段存在性、清洗工作估计）。

选择理由（2–3 段）

说明选择该数据集的分析动机、研究问题潜力、以及清洗/分析可行性。

确定里程碑

写出后续 Notebook（Final_Analysis.ipynb）要完成的任务清单（清洗项、可视化、分析问题、方法）。

要记录

比较表、选择理由、后续工作计划与时间安排。

步骤 3 — 清洗并准备数据（Notebook 2: Final_Analysis.ipynb）
目标

把选定数据集处理成可分析的干净表格，并为 EDA 与建模做好字段准备。

子步骤（按“列”/字段进行）

对每一列按以下清洗流程处理并记录决策理由（必须在 Notebook 中用 Markdown 说明每一步）：

列名规范化

小写化、去首尾空格、替换空格为下划线。

识别占位符与缺失值

把 -1, 'Unknown', '', 'NA', 'N/A' 等替换为 np.nan 或 pd.NA（选择统一缺失标识）。

记录哪些占位符被替换，以及为什么。

数据类型转换

日期：pd.to_datetime()（处理错误项 errors='coerce'），并生成衍生列（year/month/day/week等）如需。

数值：pd.to_numeric(..., errors='coerce')，处理含货币/千位符的字符串（先去除 $, ,, K 等）。

分类/字符串：.astype('category') 或保留为 str。

分类变量清洗

统一大小写与拼写（strip、lower/upper、map 映射常见拼写变体）。

合并非常稀疏类别为 Other（有理由时）。

处理同义词/缩写（建立映射字典）。

数值范围与异常值

对数值列用 IQR 或以 domain knowledge 判定上下限，决定是修正、截断、还是保留并在分析时标注。

处理缺失值策略（按列说明）

完全删除（drop rows）仅在对分析无影响且缺失占比低时使用。

填充（impute）：均值/中位数/众数、前向/后向填充、或基于分组填充。

标记缺失（新增二值 flag 列）以保留信息。

对于分类，考虑将缺失视为独立类别 'Missing'。

对于关键分析字段若缺失过多，说明影响并考虑替代字段或放弃该列。

分列/合并列

如果列中嵌套多信息（例如 "city, state" 或薪资范围），拆分为多个列并规范化。

派生/计算字段

例如：从薪资范围计算中位数、从开始/结束日期计算持续时长、从文本提取关键词计数等。

记录每个衍生字段的计算公式与意义。

重复值处理

df.duplicated() 检查并根据实际情况删除或合并重复行。

一致性与完整性校验

检查主键或联合主键是否唯一；相互依赖列是否逻辑一致（如开始 <= 结束）。

最终数据类型与存储

确认每列 final dtype（数值、类别、日期）。

将清洗后的数据导出为 data/cleaned.csv（或 parquet）并记录版本。

文档记录（Notebook 中必须包含）

每列清洗决策（为什么这么做）、替换/填充规则、被删除/保留的记录计数、以及任何无法自动处理的问题与假设。

步骤 4 — 探索性数据分析（Notebook 2）
目标

用至少三幅有意义的可视化来理解数据并为最终分析问题提供证据。

子步骤（每个图）

选择图表类型（与问题匹配）

类别对比：柱状图/箱型图/堆叠条形图。

数值分布：直方图、密度图、箱线图。

关系：散点图（可加回归线/趋势）、热力图（相关矩阵）。

时间序列：折线图（按时间聚合）。

绘图实现

使用 matplotlib / seaborn / plotly（说明选择的库）。

标题、x/y 标签、图例（若适用）、注释（指出关键观察）。

统计摘要

在图下方或旁边写 1–3 行说明：趋势、异常、对分析问题的启示。

可视化清单（至少三幅）

每幅图都要有明确目的并回答一个子问题（写出要回答的子问题）。

可选进阶

分面（facet）展示多子群体对比。

使用置信区间或误差条展示不确定性。

结果记录

保存图片到 outputs/ 并在 Notebook 中 embed（方便评阅）。

步骤 5 — 提出并回答清晰的分析问题（Notebook 2）
目标

基于 EDA 提出一个可回答的研究问题，并用数据与图表给出结论与支持证据，同时说明限制。

子步骤

定义问题

明确问题表达（一到两句话），说明因变量与自变量。

列出假设（可选：零假设/备择假设）。

选择方法

描述用来检验的统计方法/模型（例如均值比较、相关分析、回归、分组比较、卡方检验等），并说明为何合适。

实现分析

执行所选统计测试或模型：使用 scipy.stats、statsmodels、或 sklearn 等。

报告关键数值（p-value、系数、R²、置信区间等）。

展示支持性图表

基于模型或测试结果制作图表，突出关键结论。

解释结果

用语言解释数值输出的意义（例如：关系方向、显著性、效果大小）。

结论与局限

简洁总结发现（1–3 段）。

明确数据限制、可能的偏差、样本代表性问题、以及未考虑的混杂因素。

后续工作建议

可扩展分析（额外数据、不同模型、时间序列、交互项等）、或可视化增强建议。

交付物与文档（提交清单）

notebooks/Dataset_Exploration.ipynb（或每数据集各一）

notebooks/Final_Analysis.ipynb（清洗与分析、图表、结论）

data/cleaned.csv（清洗后数据）

outputs/（图表、结果文本文件）

README.md（运行说明、环境、数据来源、总结）

TESTING.md（测试记录、edge-case 处理、如何复现）

requirements.txt 或 environment.yml（环境依赖）

验证与复现（必做）

在 Notebook 最后写出复现命令（如何从原始数据运行到最终输出）。

运行一次从头到尾的“清洗 → 分析 → 导出”流程，确保无手动交互阻断（或在 README 说明需要交互的步骤）。

使用小规模抽样做单元测试：对关键清洗函数写短脚本或单元测试（可选）。

常用函数/方法速查（便于在 Notebook 中使用）

pandas：read_csv, to_csv, info, describe, isna, dropna, fillna, astype, apply, groupby, merge, pivot_table, duplicated

数值与字符串转换：pd.to_datetime, pd.to_numeric, str.replace, str.lower, str.strip, str.contains

可视化：plt.subplots, sns.histplot, sns.boxplot, sns.barplot, sns.heatmap, plt.scatter

统计/建模：scipy.stats (t-test, chi2), statsmodels.api (OLS), sklearn (train_test_split, LinearRegression, metrics)

文件/版本：git（分支、commit、push）、pip freeze 或 conda env export

最后提示（写在 Notebook 中）

在每次重大清洗或变换之后保存快照（导出中间数据文件），便于回溯。

在每个 Notebook 用 Markdown 记录你的“决策点”和“为什么做出那个选择”。

评阅时，清晰的记录和合理的假设解释往往比复杂模型更重要。